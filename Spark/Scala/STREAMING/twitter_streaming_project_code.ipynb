{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.sql.{Row, SaveMode, SparkSession}\n",
    "import org.apache.spark.sql.SQLContext\n",
    "import org.apache.spark.streaming._\n",
    "import org.apache.spark.streaming.twitter._\n",
    "import org.apache.spark.streaming.StreamingContext._\n",
    "\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "import java.text.SimpleDateFormat\n",
    "import java.util.{Calendar, Date}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/** Listens to a stream of Tweets only contains \"happy\" or \"money\" case insensitive\n",
    "you can change it to whatever keyword you want to limit to\n",
    "George Jen\n",
    "Jen Tek LLC\n",
    " */\n",
    "\n",
    " /** \n",
    "I have included working build.sbt for you to run \n",
    "sbt assembly to create jar file, check sbt sub folder for the build.sbt\n",
    "*/\n",
    " \n",
    "\n",
    "    \n",
    "    var onetime=true\n",
    "    Logger.getLogger(\"org\").setLevel(Level.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    // Configure Twitter credentials using twitter.txt\n",
    "//    setupTwitterConfig()\n",
    "    \n",
    "    val sdf = new SimpleDateFormat(\"YYYY-MM-DD hh:mm:ss\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val sparkConf = new SparkConf().setAppName(\"getTweets\").setMaster(\"local[3]\")\n",
    "    // Create the context\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     val spark = SparkSession\n",
    "          .builder()\n",
    "          .config(\"spark.master\", \"local[2]\")\n",
    "          .appName(\"interfacing spark sql to hive metastore through thrift url below\")\n",
    "          .config(\"hive.metastore.uris\", \"thrift://10.0.2.15:9083\") // replace with your hivemetastore service's thrift url\n",
    "          .enableHiveSupport() // to enable hive support\n",
    "          .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     import spark.implicits._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     spark.sql(\"CREATE TABLE IF NOT EXISTS tweets (datetime STRING, text STRING) USING hive\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    val sc=spark.sparkContext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     val ssc = new StreamingContext(sc, Seconds(1))\n",
    "    \n",
    " // specify twitter consumerKey, consumerSecret, accessToken, accessTokenSecret   \n",
    "    System.setProperty(\"twitter4j.oauth.consumerKey\",\"<your consumer Key>\")\n",
    "    System.setProperty(\"twitter4j.oauth.consumerSecret\", \"<your consumer secret>\")\n",
    "    System.setProperty(\"twitter4j.oauth.accessToken\", \"your access token\")\n",
    "    System.setProperty(\"twitter4j.oauth.accessTokenSecret\", \"your access token secret\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Connect to Twitter and get the tweets object     \n",
    "    val tweets = TwitterUtils.createStream(ssc, None)\n",
    "    \n",
    "    // Extract the text from the tweets object\n",
    "    val tweets_collection = tweets.map(each_tweet => each_tweet.getText())\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   //Set your search criteria to only retain these meet your search condition\n",
    "    val focus_tweets_collection=tweets_collection.filter(text=>text.toLowerCase.contains(\"happy\") | text.toLowerCase.contains(\"money\"))\n",
    "      \n",
    "    //iterate through DSTREAM for each RDD, show it and store tweets streaming \n",
    "    // to HIVE table, this is an example of as part of ETL to harvest and store\n",
    "    // streaming data from Twitter\n",
    "    focus_tweets_collection.foreachRDD{ rdd =>\n",
    "         if(!rdd.isEmpty) {\n",
    "             val tweetsDataFrame = rdd.toDF(\"newTweet\")\n",
    "             tweetsDataFrame.show(false)\n",
    "//             tweetsDataFrame.printSchema()\n",
    "//             println(tweetsDataFrame.count())\n",
    "//Create in memory temp view newTweets\n",
    "             tweetsDataFrame.createOrReplaceTempView(\"newTweets\")\n",
    "// Inserts the new tweets received to HIVE table tweets, with \n",
    "// current datetimestamp\n",
    "             \n",
    "             spark.sql(\"insert into tweets select from_unixtime(unix_timestamp()), * from newTweets\")\n",
    "\n",
    "        }\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "//If you intent to run it on non windows machine, change below to proper path\n",
    "//    ssc.checkpoint(\"/tmp/checkpoint/\")\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
