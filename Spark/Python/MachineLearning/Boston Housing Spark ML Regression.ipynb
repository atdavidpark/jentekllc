{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Regression with boston_data.csv. Dataset downloaded from Kaggle, to predict Boston housing price\n",
    "\n",
    "\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Code   | Description   |\n",
    "|:---|:---|\n",
    "|**CRIM** | per capita crime rate by town |\n",
    "|**ZN**  | proportion of residential land zoned for lots over 25,000 sq.ft. | \n",
    "|**INDUS**  | proportion of non-retail business acres per town | \n",
    "|**CHAS**  | Charles River dummy variable (= 1 if tract bounds river; 0 otherwise) | \n",
    "|**NOX**  | nitric oxides concentration (parts per 10 million) | \n",
    "|**RM**  | average number of rooms per dwelling | \n",
    "|**AGE**  | proportion of owner-occupied units built prior to 1940 | \n",
    "|**DIS**  | weighted distances to five Boston employment centres | \n",
    "|**RAD**  | index of accessibility to radial highways | \n",
    "|**TAX**  | full-value property-tax rate per $10,000 | \n",
    "|**PTRATIO**  | pupil-teacher ratio by town | \n",
    "|**B**  | 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town | \n",
    "|**LSTAT**  | % lower status of the population | \n",
    "|**MEDV**  | Median value of owner-occupied homes in \\$1000's | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>mdev is the label, all other columns are features. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> Import PySpark libraries, create SparkContext and SQL context, then load the csv data file. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sc.stop()\n",
    "sc= SparkContext()\n",
    "sqlContext = SQLContext(sc)\n",
    "boston_house_df = sqlContext.read.format('csv').options(header='true', inferschema='true').load('file:///opt/spark/data/data_compare/boston_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5> Show statistics of each column, including feature columns and label column (medv)  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crim</th>\n",
       "      <td>404</td>\n",
       "      <td>3.7309119306930723</td>\n",
       "      <td>8.943922212251913</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zn</th>\n",
       "      <td>404</td>\n",
       "      <td>10.509900990099009</td>\n",
       "      <td>22.053733184762923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indus</th>\n",
       "      <td>404</td>\n",
       "      <td>11.189900990099002</td>\n",
       "      <td>6.8149093223650885</td>\n",
       "      <td>0.46</td>\n",
       "      <td>27.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chas</th>\n",
       "      <td>404</td>\n",
       "      <td>0.06930693069306931</td>\n",
       "      <td>0.25429026389960196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nox</th>\n",
       "      <td>404</td>\n",
       "      <td>0.5567103960396043</td>\n",
       "      <td>0.11732064984156548</td>\n",
       "      <td>0.392</td>\n",
       "      <td>0.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rm</th>\n",
       "      <td>404</td>\n",
       "      <td>6.301450495049499</td>\n",
       "      <td>0.6758302935149543</td>\n",
       "      <td>3.561</td>\n",
       "      <td>8.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>404</td>\n",
       "      <td>68.60173267326732</td>\n",
       "      <td>28.066142579151702</td>\n",
       "      <td>2.9</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dis</th>\n",
       "      <td>404</td>\n",
       "      <td>3.7996663366336647</td>\n",
       "      <td>2.1099159643057357</td>\n",
       "      <td>1.1691</td>\n",
       "      <td>12.1265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rad</th>\n",
       "      <td>404</td>\n",
       "      <td>9.836633663366337</td>\n",
       "      <td>8.834741064787444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tax</th>\n",
       "      <td>404</td>\n",
       "      <td>411.68811881188117</td>\n",
       "      <td>171.07355305036535</td>\n",
       "      <td>187.0</td>\n",
       "      <td>711.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptratio</th>\n",
       "      <td>404</td>\n",
       "      <td>18.444554455445505</td>\n",
       "      <td>2.150294584124713</td>\n",
       "      <td>12.6</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>404</td>\n",
       "      <td>355.06824257425643</td>\n",
       "      <td>94.48957234802008</td>\n",
       "      <td>0.32</td>\n",
       "      <td>396.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lstat</th>\n",
       "      <td>404</td>\n",
       "      <td>12.598935643564351</td>\n",
       "      <td>6.925172524716524</td>\n",
       "      <td>1.73</td>\n",
       "      <td>34.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medv</th>\n",
       "      <td>404</td>\n",
       "      <td>22.312376237623763</td>\n",
       "      <td>8.83701864645797</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0                    1                    2        3        4\n",
       "summary  count                 mean               stddev      min      max\n",
       "crim       404   3.7309119306930723    8.943922212251913  0.00632  88.9762\n",
       "zn         404   10.509900990099009   22.053733184762923      0.0     95.0\n",
       "indus      404   11.189900990099002   6.8149093223650885     0.46    27.74\n",
       "chas       404  0.06930693069306931  0.25429026389960196      0.0      1.0\n",
       "nox        404   0.5567103960396043  0.11732064984156548    0.392    0.871\n",
       "rm         404    6.301450495049499   0.6758302935149543    3.561     8.78\n",
       "age        404    68.60173267326732   28.066142579151702      2.9    100.0\n",
       "dis        404   3.7996663366336647   2.1099159643057357   1.1691  12.1265\n",
       "rad        404    9.836633663366337    8.834741064787444      1.0     24.0\n",
       "tax        404   411.68811881188117   171.07355305036535    187.0    711.0\n",
       "ptratio    404   18.444554455445505    2.150294584124713     12.6     22.0\n",
       "black      404   355.06824257425643    94.48957234802008     0.32    396.9\n",
       "lstat      404   12.598935643564351    6.925172524716524     1.73    34.37\n",
       "medv       404   22.312376237623763     8.83701864645797      5.0     50.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_house_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "We need to find out corelationship beween each feature column with label medv.  The corelationship is between 0 to |1|, the more close to -1, or 1, that means that feature column is more negatively or positively corelated to medv, the more close to 0, that means less or little corelationship between the feature column and label medv.\n",
    "\n",
    "   \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation to medv for  crim -0.4009558757372438\n",
      "Correlation to medv for  zn 0.355607582415516\n",
      "Correlation to medv for  indus -0.5016982293419979\n",
      "Correlation to medv for  chas 0.14140044808241922\n",
      "Correlation to medv for  nox -0.4392251926056786\n",
      "Correlation to medv for  rm 0.6835409939262136\n",
      "Correlation to medv for  age -0.39086335148339485\n",
      "Correlation to medv for  dis 0.26487595153417776\n",
      "Correlation to medv for  rad -0.4235083975722877\n",
      "Correlation to medv for  tax -0.49579240671703434\n",
      "Correlation to medv for  ptratio -0.5063125552383506\n",
      "Correlation to medv for  black 0.36007109188975617\n",
      "Correlation to medv for  lstat -0.7426954940642168\n",
      "Correlation to medv for  medv 1.0\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "for i in boston_house_df.columns:\n",
    "    if not( isinstance(boston_house_df.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to medv for \", i, boston_house_df.stat.corr('medv',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Spark ML requires features of the dataset are vectorized before the dataset can be fit into ML model, \n",
    "VectorAssembler is to convert a Spark Dataframe into Spark Vectorized Dataframe\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|medv|\n",
      "+--------------------+----+\n",
      "|[0.15876,0.0,10.8...|21.7|\n",
      "|[0.10328,25.0,5.1...|19.6|\n",
      "+--------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat'], outputCol = 'features')\n",
    "#vectorAssembler = VectorAssembler(inputCols = ['rm'], outputCol = 'features')\n",
    "vector_house_df = vectorAssembler.transform(boston_house_df)\n",
    "vector_house_df = vector_house_df.select(['features', 'medv'])\n",
    "vector_house_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>  \n",
    "\n",
    "Now randomly split Spark Vectorized DataFrame (dataset) into training data (70%) and testing data (30%)\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n"
     ]
    }
   ],
   "source": [
    "splits = vector_house_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]\n",
    "print(test_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|medv|\n",
      "+--------------------+----+\n",
      "|[0.01301,35.0,1.5...|32.7|\n",
      "|[0.01381,80.0,0.4...|50.0|\n",
      "+--------------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Let's do Linear Regression first, fit the Linear Regression model with train_df\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.04605858960728708,0.0009782224296996135,-0.012130255724909542,1.6497514727852698,-5.725161579044625,4.364815635088261,0.0,-0.5725774171192526,0.0,0.0,-0.8172417837138445,0.007950352749432139,-0.49227049878479]\n",
      "Intercept: 18.969627314022954\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='medv', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "Linear Regression produced slope coefficients and intercept\n",
    "\n",
    "y=a1 X x1 + a2 X x2 +...+ an X xn + b\n",
    "\n",
    "a1,a2,...an are coefficients for the xn in their space\n",
    "b is intercept\n",
    "\n",
    "x1, x2, ... xn are independent variables\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.514423\n",
      "r2: 0.734197\n"
     ]
    }
   ],
   "source": [
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              medv|\n",
      "+-------+------------------+\n",
      "|  count|               301|\n",
      "|   mean|22.162458471760797|\n",
      "| stddev| 8.770922752810543|\n",
      "|    min|               5.0|\n",
      "|    max|              50.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n",
    "\n",
    "  \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|medv|            features|\n",
      "+------------------+----+--------------------+\n",
      "|26.276616151728096|33.0|[0.01951,17.5,1.3...|\n",
      "| 38.45717891007576|50.0|[0.02009,95.0,2.6...|\n",
      "| 26.78556110995195|16.5|[0.02498,0.0,1.89...|\n",
      "|28.312244074548467|30.8|[0.02763,75.0,2.9...|\n",
      "|26.387800739076635|25.0|[0.02875,28.0,15....|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.707176\n"
     ]
    }
   ],
   "source": [
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"medv\",\"features\").show(5)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 4.87695\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numIterations: 11\n",
      "objectiveHistory: [0.5000000000000004, 0.43301699522033144, 0.232197220657441, 0.2072378796302617, 0.17607126421866942, 0.17384247862056668, 0.1731252493266702, 0.1714446715795995, 0.17116908096115527, 0.17103599732933553, 0.17092588169896675]\n",
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "|-6.435796203387795|\n",
      "|0.9012965616796755|\n",
      "+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|medv|            features|\n",
      "+------------------+----+--------------------+\n",
      "|26.276616151728096|33.0|[0.01951,17.5,1.3...|\n",
      "| 38.45717891007576|50.0|[0.02009,95.0,2.6...|\n",
      "| 26.78556110995195|16.5|[0.02498,0.0,1.89...|\n",
      "|28.312244074548467|30.8|[0.02763,75.0,2.9...|\n",
      "|26.387800739076635|25.0|[0.02875,28.0,15....|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "predictions.select(\"prediction\",\"medv\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "    \n",
    "Now try Gradient Boost Tree Regressor with the same train_df and test_df \n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GBTRegressor(featuresCol=\"features\",labelCol='medv', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|medv|            features|\n",
      "+------------------+----+--------------------+\n",
      "| 27.82113650393453|24.0|[0.00632,18.0,2.3...|\n",
      "|19.633749465438637|18.9|[0.0136,75.0,4.0,...|\n",
      "|30.478603890145347|29.1|[0.01439,60.0,2.9...|\n",
      "|28.708202626278265|24.5|[0.01501,80.0,2.0...|\n",
      "|22.722511085699136|21.6|[0.02731,0.0,7.07...|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select(\"prediction\",\"medv\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n",
    "\n",
    "Looks like the metrics of Gradient Boost Tree are better that those of Linear Regressor\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.788076\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "gbt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 3.73236\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Now try Random Forest Regressor with the same train_df and test_df\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestRegressor(featuresCol=\"features\",labelCol='medv', maxDepth=3)\n",
    "rf_model = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|medv|            features|\n",
      "+------------------+----+--------------------+\n",
      "|27.388638589503927|24.0|[0.00632,18.0,2.3...|\n",
      "|22.301061336550966|18.9|[0.0136,75.0,4.0,...|\n",
      "| 28.23928643587368|29.1|[0.01439,60.0,2.9...|\n",
      "| 25.37852450611539|24.5|[0.01501,80.0,2.0...|\n",
      "| 23.28916174580568|21.6|[0.02731,0.0,7.07...|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predictions = rf_model.transform(test_df)\n",
    "rf_predictions.select(\"prediction\",\"medv\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "    \n",
    "Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n",
    "\n",
    "Looks like the metrics of Random Forest are better that those of Linear Regressor, but similar to those of Gradient Boost Tree\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "rf_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % rf_evaluator.evaluate(rf_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 3.73236\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on test data = %g\" % gbt_evaluator.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "Finally, try Decision Tree regressor with the same train_df and test_df\n",
    "    \n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol=\"features\",labelCol='medv', maxDepth=3)\n",
    "dt_model = dt.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----+--------------------+\n",
      "|        prediction|medv|            features|\n",
      "+------------------+----+--------------------+\n",
      "|26.283050847457623|24.0|[0.00632,18.0,2.3...|\n",
      "|            21.025|18.9|[0.0136,75.0,4.0,...|\n",
      "|26.283050847457623|29.1|[0.01439,60.0,2.9...|\n",
      "|26.283050847457623|24.5|[0.01501,80.0,2.0...|\n",
      "|            21.025|21.6|[0.02731,0.0,7.07...|\n",
      "+------------------+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select(\"prediction\",\"medv\",\"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "    \n",
    "Test the model with test_df, testing produces metrics that evaluates the performance of the regressor with RMSE and R2 score.\n",
    "\n",
    "Looks like the metrics of Decision Tree Regressor are slightly better than that those of Linear Regressor, but not as good as Gradient Boost Tree and Random Forest\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared (R2) on test data = 0.727042\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % dt_evaluator.evaluate(dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"medv\",metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 4.70311\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on test data = %g\" % dt_evaluator.evaluate(dt_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5>\n",
    "\n",
    "This concludes the testing of Spark ML regressors\n",
    "\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
