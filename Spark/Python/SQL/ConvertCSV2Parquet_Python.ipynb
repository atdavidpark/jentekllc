{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#George Jen, Jen Tek LLC\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.getOrCreate()\n",
    "#Read Data\n",
    "#df = spark.read.csv(\"datasets/SMSSpamCollection\", sep = \"\\t\", inferSchema=True, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logger.getLogger(\"org\").setLevel(Level.ERROR)\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"csv2parquet\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///d:/tmp\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"quote\", \"\\\"\").load(\"D:/teaching/scala/ticker_symbol.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------+--------+---------------------------+--------------+----+\n",
      "|Ticker|Name                        |Exchange|CategoryName               |CategoryNumber|_c5 |\n",
      "+------+----------------------------+--------+---------------------------+--------------+----+\n",
      "|AUB.AX|Austbrokers Holdings Limited|ASX     |Accident & Health Insurance|431           |null|\n",
      "|GLRE  |Greenlight Capital Re, Ltd. |NMS     |Accident & Health Insurance|431           |null|\n",
      "+------+----------------------------+--------+---------------------------+--------------+----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds.show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "heading = [\"Ticker\",\"Name\",\"Exchange\",\"CategoryName\",\"CategoryNumber\",\"_c5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.toDF(*heading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------+--------+---------------------------+--------------+----+\n",
      "|Ticker|Name                         |Exchange|CategoryName               |CategoryNumber|_c5 |\n",
      "+------+-----------------------------+--------+---------------------------+--------------+----+\n",
      "|AUB.AX|Austbrokers Holdings Limited |ASX     |Accident & Health Insurance|431           |null|\n",
      "|GLRE  |Greenlight Capital Re, Ltd.  |NMS     |Accident & Health Insurance|431           |null|\n",
      "|SFG   |StanCorp Financial Group Inc.|NYQ     |Accident & Health Insurance|431           |null|\n",
      "+------+-----------------------------+--------+---------------------------+--------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------+--------+---------------------------+--------------+\n",
      "|Ticker|Name                         |Exchange|CategoryName               |CategoryNumber|\n",
      "+------+-----------------------------+--------+---------------------------+--------------+\n",
      "|AUB.AX|Austbrokers Holdings Limited |ASX     |Accident & Health Insurance|431           |\n",
      "|GLRE  |Greenlight Capital Re, Ltd.  |NMS     |Accident & Health Insurance|431           |\n",
      "|SFG   |StanCorp Financial Group Inc.|NYQ     |Accident & Health Insurance|431           |\n",
      "+------+-----------------------------+--------+---------------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#When the CSV file was read into DataFrame, all fields are String, below is to cast it to\n",
    "#what the data should be, such as cast CategoryNumber to Int\n",
    "\n",
    "df_with_datatype=df.selectExpr(\"Ticker\",\\\n",
    "                  \"Name\", \\\n",
    "                  \"Exchange\",\\\n",
    "                  \"CategoryName\",\\\n",
    "                  \"cast(CategoryNumber as int) CategoryNumber\")\n",
    "\n",
    "df_with_datatype.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the DataFrame to Parquet format, overwrite if existing.\n",
    "#Parquet is Columnar, good for Analytics query.\n",
    "\n",
    "df_with_datatype.write.mode(\"Overwrite\").parquet(\"D:/teaching/scala/ticker_symbol.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------------------+--------+---------------------------+--------------+\n",
      "|Ticker|Name                         |Exchange|CategoryName               |CategoryNumber|\n",
      "+------+-----------------------------+--------+---------------------------+--------------+\n",
      "|AUB.AX|Austbrokers Holdings Limited |ASX     |Accident & Health Insurance|431           |\n",
      "|GLRE  |Greenlight Capital Re, Ltd.  |NMS     |Accident & Health Insurance|431           |\n",
      "|SFG   |StanCorp Financial Group Inc.|NYQ     |Accident & Health Insurance|431           |\n",
      "+------+-----------------------------+--------+---------------------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the Parquet data back and run SQL query on it\n",
    "\n",
    "read_parquet_df = spark.read.parquet(\"D:/teaching/scala/ticker_symbol.parquet\")\n",
    "\n",
    "read_parquet_df.show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Ticker: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Exchange: string (nullable = true)\n",
      " |-- CategoryName: string (nullable = true)\n",
      " |-- CategoryNumber: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TickerSymbol = read_parquet_df.toDF(\"Ticker\",\"Name\",\"Exchange\",\"CategoryName\",\"CategoryNumber\")\n",
    "TickerSymbol.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------+--------+-------------------------------+--------------+\n",
      "|Ticker|Name                                       |Exchange|CategoryName                   |CategoryNumber|\n",
      "+------+-------------------------------------------+--------+-------------------------------+--------------+\n",
      "|MSFT  |Microsoft Corporation                      |NMS     |Business Software & Services   |826           |\n",
      "|HPQ   |Hewlett-Packard Company                    |NYQ     |Diversified Computer Systems   |810           |\n",
      "|GE    |General Electric Company                   |NYQ     |Diversified Machinery          |622           |\n",
      "|IBM   |International Business Machines Corporation|NYQ     |Information Technology Services|824           |\n",
      "+------+-------------------------------------------+--------+-------------------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TickerSymbol.createOrReplaceTempView(\"TickerSymbol\")\n",
    "spark.sql(\"SELECT * from TickerSymbol where Ticker in ('IBM','MSFT','HPQ','GE')\").show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
